{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from -r requirements.txt (line 1)) (1.24.10)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from -r requirements.txt (line 2)) (10.2.0)\n",
      "Collecting llama-index (from -r requirements.txt (line 3))\n",
      "  Downloading llama_index-0.11.13-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-core (from -r requirements.txt (line 4))\n",
      "  Downloading llama_index_core-0.11.13.post1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-llms-openai (from -r requirements.txt (line 5))\n",
      "  Downloading llama_index_llms_openai-0.2.9-py3-none-any.whl.metadata (648 bytes)\n",
      "Requirement already satisfied: requests in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from -r requirements.txt (line 6)) (2.32.3)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.10 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from pymupdf->-r requirements.txt (line 1)) (1.24.10)\n",
      "Collecting llama-index-agent-openai<0.4.0,>=0.3.4 (from llama-index->-r requirements.txt (line 3))\n",
      "  Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-cli<0.4.0,>=0.3.1 (from llama-index->-r requirements.txt (line 3))\n",
      "  Downloading llama_index_cli-0.3.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.3.0,>=0.2.4 (from llama-index->-r requirements.txt (line 3))\n",
      "  Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl.metadata (686 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index->-r requirements.txt (line 3))\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index->-r requirements.txt (line 3))\n",
      "  Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama-index->-r requirements.txt (line 3))\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.2.1-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama-index->-r requirements.txt (line 3))\n",
      "  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama-index->-r requirements.txt (line 3))\n",
      "  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.3.0,>=0.2.0 (from llama-index->-r requirements.txt (line 3))\n",
      "  Downloading llama_index_readers_file-0.2.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.3.0 (from llama-index->-r requirements.txt (line 3))\n",
      "  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index->-r requirements.txt (line 3))\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core->-r requirements.txt (line 4)) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (3.10.5)\n",
      "Collecting dataclasses-json (from llama-index-core->-r requirements.txt (line 4))\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core->-r requirements.txt (line 4))\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core->-r requirements.txt (line 4))\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core->-r requirements.txt (line 4))\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: httpx in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core->-r requirements.txt (line 4))\n",
      "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (1.24.4)\n",
      "Collecting pydantic<3.0.0,>=2.7.0 (from llama-index-core->-r requirements.txt (line 4))\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "     ---------------------------------------- 0.0/149.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 149.4/149.4 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from llama-index-core->-r requirements.txt (line 4)) (4.11.0)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core->-r requirements.txt (line 4))\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core->-r requirements.txt (line 4))\n",
      "  Downloading wrapt-1.16.0-cp38-cp38-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting openai<2.0.0,>=1.40.0 (from llama-index-llms-openai->-r requirements.txt (line 5))\n",
      "  Downloading openai-1.47.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from requests->-r requirements.txt (line 6)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from requests->-r requirements.txt (line 6)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from requests->-r requirements.txt (line 6)) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from requests->-r requirements.txt (line 6)) (2021.5.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (1.10.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core->-r requirements.txt (line 4)) (4.0.3)\n",
      "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index->-r requirements.txt (line 3))\n",
      "  Downloading llama_cloud-0.1.0-py3-none-any.whl.metadata (750 bytes)\n",
      "Requirement already satisfied: pandas in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index->-r requirements.txt (line 3)) (2.0.3)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index->-r requirements.txt (line 3)) (4.12.3)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index->-r requirements.txt (line 3))\n",
      "  Using cached pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index->-r requirements.txt (line 3))\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.3.0->llama-index->-r requirements.txt (line 3))\n",
      "  Downloading llama_parse-0.5.6-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: click in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 3)) (8.0.1)\n",
      "Collecting joblib (from nltk>3.8.1->llama-index->-r requirements.txt (line 3))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 3)) (2024.7.24)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai->-r requirements.txt (line 5)) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai->-r requirements.txt (line 5)) (1.9.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->llama-index-llms-openai->-r requirements.txt (line 5))\n",
      "  Downloading jiter-0.5.0-cp38-none-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from httpx->llama-index-core->-r requirements.txt (line 4)) (1.0.5)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core->-r requirements.txt (line 4))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core->-r requirements.txt (line 4)) (0.7.0)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3.0.0,>=2.7.0->llama-index-core->-r requirements.txt (line 4))\n",
      "  Downloading pydantic_core-2.23.4-cp38-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core->-r requirements.txt (line 4)) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core->-r requirements.txt (line 4)) (0.4.6)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core->-r requirements.txt (line 4))\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core->-r requirements.txt (line 4))\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai->-r requirements.txt (line 5)) (1.2.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index->-r requirements.txt (line 3)) (2.5)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core->-r requirements.txt (line 4)) (24.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index->-r requirements.txt (line 3)) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index->-r requirements.txt (line 3)) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hoangphuc\\anaconda3\\envs\\mfea\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index->-r requirements.txt (line 3)) (1.16.0)\n",
      "Downloading llama_index-0.11.13-py3-none-any.whl (6.8 kB)\n",
      "Downloading llama_index_core-0.11.13.post1-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 0.6/1.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.4/1.6 MB 14.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 12.5 MB/s eta 0:00:00\n",
      "Downloading llama_index_llms_openai-0.2.9-py3-none-any.whl (12 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "   ---------------------------------------- 0.0/179.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 179.3/179.3 kB 10.6 MB/s eta 0:00:00\n",
      "Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.3.1-py3-none-any.whl (27 kB)\n",
      "Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl (6.1 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl (10 kB)\n",
      "Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 1.0/1.2 MB 32.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 19.2 MB/s eta 0:00:00\n",
      "Downloading llama_index_multi_modal_llms_openai-0.2.1-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.2.2-py3-none-any.whl (38 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\n",
      "Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading openai-1.47.1-py3-none-any.whl (375 kB)\n",
      "   ---------------------------------------- 0.0/375.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 375.6/375.6 kB 11.4 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "   ---------------------------------------- 0.0/434.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 434.9/434.9 kB 13.7 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.23.4-cp38-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 1.0/1.9 MB 21.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.7/1.9 MB 22.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 13.5 MB/s eta 0:00:00\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading wrapt-1.16.0-cp38-cp38-win_amd64.whl (37 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading jiter-0.5.0-cp38-none-win_amd64.whl (192 kB)\n",
      "   ---------------------------------------- 0.0/192.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 192.7/192.7 kB 11.4 MB/s eta 0:00:00\n",
      "Downloading llama_cloud-0.1.0-py3-none-any.whl (176 kB)\n",
      "   ---------------------------------------- 0.0/176.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 176.3/176.3 kB 10.4 MB/s eta 0:00:00\n",
      "Downloading llama_parse-0.5.6-py3-none-any.whl (10 kB)\n",
      "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.3/49.3 kB 2.4 MB/s eta 0:00:00\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: striprtf, dirtyjson, wrapt, pypdf, pydantic-core, networkx, mypy-extensions, marshmallow, joblib, jiter, h11, fsspec, typing-inspect, pydantic, nltk, deprecated, dataclasses-json, openai, llama-index-core, llama-cloud, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-legacy, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.20.1\n",
      "    Uninstalling pydantic_core-2.20.1:\n",
      "      Successfully uninstalled pydantic_core-2.20.1\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.12.0\n",
      "    Uninstalling h11-0.12.0:\n",
      "      Successfully uninstalled h11-0.12.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.8.2\n",
      "    Uninstalling pydantic-1.8.2:\n",
      "      Successfully uninstalled pydantic-1.8.2\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.37.1\n",
      "    Uninstalling openai-1.37.1:\n",
      "      Successfully uninstalled openai-1.37.1\n",
      "Successfully installed dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 fsspec-2024.9.0 h11-0.14.0 jiter-0.5.0 joblib-1.4.2 llama-cloud-0.1.0 llama-index-0.11.13 llama-index-agent-openai-0.3.4 llama-index-cli-0.3.1 llama-index-core-0.11.13.post1 llama-index-embeddings-openai-0.2.5 llama-index-indices-managed-llama-cloud-0.4.0 llama-index-legacy-0.9.48.post3 llama-index-llms-openai-0.2.9 llama-index-multi-modal-llms-openai-0.2.1 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.2.2 llama-index-readers-llama-parse-0.3.0 llama-parse-0.5.6 marshmallow-3.22.0 mypy-extensions-1.0.0 networkx-3.1 nltk-3.9.1 openai-1.47.1 pydantic-2.9.2 pydantic-core-2.23.4 pypdf-4.3.1 striprtf-0.0.26 typing-inspect-0.9.0 wrapt-1.16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: celery 5.0.5 has a non-standard dependency specifier pytz>dev. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of celery or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastapi 0.68.1 requires pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2, but you have pydantic 2.9.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_data.parse_data import ParseHandler\n",
    "from preprocess_data.chunking import ChunkHandler\n",
    "import os\n",
    "import io\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsehandler = ParseHandler.get_instance(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_stream(file_path):\n",
    "    with open(file_path, 'rb') as pdf_file:\n",
    "        pdf_content = pdf_file.read()\n",
    "        pdf_stream = io.BytesIO(pdf_content)\n",
    "    return pdf_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'thuvienphapluat/law_2. Tai lieu Khach hang cung cap_5. Salary Regulation 2024 (V) (1).pdf'\n",
    "pdf_stream = pdf_to_stream(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_base64s = parsehandler.pdf_to_images(file_stream=pdf_stream, pdf_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_base64s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing(file_stream, pdf_path):\n",
    "    parsehandler = ParseHandler.get_instance(api_key=api_key)\n",
    "    image_base64s = parsehandler.pdf_to_images(file_stream, pdf_path)\n",
    "    pages, pdf_info, tables, equations = parsehandler.parse_pdf(image_base64s, pdf_path)\n",
    "    return pages, pdf_info, tables, equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "pages, pdf_info, tables, equations = parsing(pdf_stream, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = {\"pages\": pages, \"pdf_info\": pdf_info, \"tables\": tables, \"equations\": equations}\n",
    "with open(\"parsing_result/Salary_regulation(V).json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(data, json_file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"parsing_result/Salary_regulation(V).json\", \"r\", encoding=\"utf-8\") as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"parsing_result/tables.md\", \"a\", encoding=\"utf-8\") as file:\n",
    "    for table in data[\"tables\"]:\n",
    "        file.write(table[\"content\"] + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"parsing_result/equations.md\", \"a\", encoding=\"utf-8\") as file:\n",
    "    for equation in data[\"equations\"]:\n",
    "        file.write(equation[\"content\"] + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages, pdf_info, tables, equations = data[\"pages\"], data[\"pdf_info\"], data[\"tables\"], data[\"equations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"parsing_result/Salary_regulation(V).md\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(pdf_info[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkhandler = ChunkHandler.get_instance(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = chunkhandler.create_article(pdf_info, pages)\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forms = chunkhandler.create_form(pdf_info, pages)\n",
    "len(forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbls = chunkhandler.create_table(tables)\n",
    "len(tbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqts = chunkhandler.create_equation(equations)\n",
    "len(eqts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk.extend(articles)\n",
    "chunk.extend(tbls)\n",
    "chunk.extend(eqts)\n",
    "chunk.extend(forms)\n",
    "len(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"parsing_result/Salary_regulation(V)_chunk.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(chunk, json_file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
